{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7270fbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 65 unique characters in our vocabulary\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"We have {vocab_size} unique characters in our vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc22820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utf_ids = text.encode('utf-8')\n",
    "utf_ids = list(map(int, utf_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7968facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pair_counts_dict(utf_ids):\n",
    "    counts = {}\n",
    "    for pair in zip(utf_ids, utf_ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1386572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_replace_pairs(utf_ids, pair, new_id):\n",
    "    new_utf_ids = []\n",
    "    i = 0\n",
    "    while i < len(utf_ids):\n",
    "        if i < len(utf_ids) - 1 and utf_ids[i] == pair[0] and utf_ids[i+1] == pair[1]:\n",
    "            new_utf_ids.append(new_id)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_utf_ids.append(utf_ids[i])\n",
    "            i += 1\n",
    "    return new_utf_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01aa91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_merges = 128\n",
    "new_id = 256\n",
    "\n",
    "new_utf_ids = utf_ids.copy()\n",
    "merges_map = {}\n",
    "\n",
    "for i in range(num_merges):\n",
    "    pair_counts_dict = get_pair_counts_dict(new_utf_ids)\n",
    "    max_count_pair = max(pair_counts_dict, key=pair_counts_dict.get)\n",
    "    new_id = 256 + i\n",
    "    new_utf_ids = merge_and_replace_pairs(new_utf_ids, max_count_pair, new_id)\n",
    "    merges_map[max_count_pair] = new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac07e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_map = {old_id: bytes([old_id]) for old_id in range(256)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d86148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ((id_1, id_2), new_id) in merges_map.items():\n",
    "    byte_map[new_id] = byte_map[id_1] + byte_map[id_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7485addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ids_to_string(ids_list):\n",
    "    return b\"\".join(byte_map[i] for i in ids_list).decode('utf-8', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac8da4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string_to_ids(text):\n",
    "    utf_ids = list(text.encode('utf-8'))    \n",
    "    while len(utf_ids) >= 2:\n",
    "        pair_counts_dict = get_pair_counts_dict(utf_ids)\n",
    "        pair = min(pair_counts_dict, key=lambda p: merges_map.get(p, float('inf')))\n",
    "        if pair not in merges_map:\n",
    "            break\n",
    "        utf_id = merges_map[pair]\n",
    "        utf_ids = merge_and_replace_pairs(utf_ids, pair, utf_id)\n",
    "    return utf_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bf33c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encode_string_to_ids(\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13473f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['l', 'ow', 'er']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[byte_map[i].decode('utf-8') for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af32b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "gpt2regex = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cfe351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open('encoder.json', 'r') as file:\n",
    "    gpt2_byte_map = json.load(file)\n",
    "    \n",
    "with open('vocab.bpe', 'r', encoding='utf-8') as file:\n",
    "    bpe_data = file.read()\n",
    "gpt2_merges_map = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
